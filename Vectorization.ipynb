{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T09:30:28.662797Z",
     "start_time": "2019-02-04T09:29:32.668122Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "google_vec_file = '~/Downloads/GoogleNews-vectors-negative300.bin'\n",
    "google_model = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T09:33:08.912318Z",
     "start_time": "2019-02-04T09:33:08.646231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datemess</th>\n",
       "      <th>messages</th>\n",
       "      <th>rp_page</th>\n",
       "      <th>su_follow</th>\n",
       "      <th>botActive</th>\n",
       "      <th>botCreated</th>\n",
       "      <th>datepage</th>\n",
       "      <th>fans</th>\n",
       "      <th>pagename</th>\n",
       "      <th>firstContactDate</th>\n",
       "      <th>lastContactDate</th>\n",
       "      <th>gender</th>\n",
       "      <th>timezone</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-26 05:28:12.281</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1748596732049183</td>\n",
       "      <td>1773780432666739</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-19 13:33:14.479</td>\n",
       "      <td>1349</td>\n",
       "      <td>JokeBot</td>\n",
       "      <td>2017-11-17T04:33:49.265Z</td>\n",
       "      <td>2017-11-17T04:33:49.373Z</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>en_US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-26 05:28:12.280</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1748596732049183</td>\n",
       "      <td>1773780432666739</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-19 13:33:14.479</td>\n",
       "      <td>1349</td>\n",
       "      <td>JokeBot</td>\n",
       "      <td>2017-11-17T04:33:49.265Z</td>\n",
       "      <td>2017-11-17T04:33:49.373Z</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>en_US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-26 10:00:03.962</td>\n",
       "      <td>no</td>\n",
       "      <td>1748596732049183</td>\n",
       "      <td>1714087635268143</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-19 13:33:14.479</td>\n",
       "      <td>1349</td>\n",
       "      <td>JokeBot</td>\n",
       "      <td>2017-11-17T05:55:53.814Z</td>\n",
       "      <td>2017-11-17T07:19:19.688Z</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>en_US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-27 08:15:06.328</td>\n",
       "      <td>More Puns</td>\n",
       "      <td>1748596732049183</td>\n",
       "      <td>1714087635268143</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-19 13:33:14.479</td>\n",
       "      <td>1349</td>\n",
       "      <td>JokeBot</td>\n",
       "      <td>2017-11-17T05:55:53.814Z</td>\n",
       "      <td>2017-11-17T07:19:19.688Z</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>en_US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-27 08:15:20.982</td>\n",
       "      <td>Give me more puns!</td>\n",
       "      <td>1748596732049183</td>\n",
       "      <td>1714087635268143</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-19 13:33:14.479</td>\n",
       "      <td>1349</td>\n",
       "      <td>JokeBot</td>\n",
       "      <td>2017-11-17T05:55:53.814Z</td>\n",
       "      <td>2017-11-17T07:19:19.688Z</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>en_US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datemess            messages           rp_page  \\\n",
       "0 2018-07-26 05:28:12.281                 Yes  1748596732049183   \n",
       "1 2018-07-26 05:28:12.280                 Yes  1748596732049183   \n",
       "2 2018-07-26 10:00:03.962                  no  1748596732049183   \n",
       "3 2018-07-27 08:15:06.328           More Puns  1748596732049183   \n",
       "4 2018-07-27 08:15:20.982  Give me more puns!  1748596732049183   \n",
       "\n",
       "          su_follow  botActive  botCreated                datepage  fans  \\\n",
       "0  1773780432666739      False        True 2017-07-19 13:33:14.479  1349   \n",
       "1  1773780432666739      False        True 2017-07-19 13:33:14.479  1349   \n",
       "2  1714087635268143      False        True 2017-07-19 13:33:14.479  1349   \n",
       "3  1714087635268143      False        True 2017-07-19 13:33:14.479  1349   \n",
       "4  1714087635268143      False        True 2017-07-19 13:33:14.479  1349   \n",
       "\n",
       "  pagename          firstContactDate           lastContactDate  gender  \\\n",
       "0  JokeBot  2017-11-17T04:33:49.265Z  2017-11-17T04:33:49.373Z    male   \n",
       "1  JokeBot  2017-11-17T04:33:49.265Z  2017-11-17T04:33:49.373Z    male   \n",
       "2  JokeBot  2017-11-17T05:55:53.814Z  2017-11-17T07:19:19.688Z  female   \n",
       "3  JokeBot  2017-11-17T05:55:53.814Z  2017-11-17T07:19:19.688Z  female   \n",
       "4  JokeBot  2017-11-17T05:55:53.814Z  2017-11-17T07:19:19.688Z  female   \n",
       "\n",
       "   timezone locale  \n",
       "0       2.0  en_US  \n",
       "1       2.0  en_US  \n",
       "2       8.0  en_US  \n",
       "3       8.0  en_US  \n",
       "4       8.0  en_US  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('mergedmess.pkl','rb') as file:\n",
    "    mergedmess = pickle.load(file)\n",
    "\n",
    "mergedmess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization with Google Gensim's Pre-trained W2V Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T09:33:14.477733Z",
     "start_time": "2019-02-04T09:33:14.469795Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_doc_vec(words, model):\n",
    "    good_words = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            if model.wv[word] is not None:\n",
    "                good_words.append(word)\n",
    "        except:\n",
    "            continue\n",
    "    if len(good_words) == 0:\n",
    "        return None\n",
    "    return model.wv[good_words].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T09:47:37.457436Z",
     "start_time": "2019-02-04T09:47:25.840168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def google_vec(text):\n",
    "    # Make a copy of the text dataframe for the Google work\n",
    "    textual = text.copy()\n",
    "\n",
    "    textual['messages'] = textual['messages'].str.lower()\n",
    "    textual.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Retrieve the document vectors based on google word vectors\n",
    "    textual_google_vecs = textual['messages'].str.split().map(lambda x: get_doc_vec(x, google_model))\n",
    "\n",
    "    # Add to dataframe\n",
    "    textual['vecs'] = textual_google_vecs\n",
    "\n",
    "    # Drop the bad docs\n",
    "    textual = textual.dropna()\n",
    "\n",
    "    # Create a Numpy array of the document vectors\n",
    "    textual_np_vecs = np.zeros((len(textual), 300))\n",
    "    for i, vec in enumerate(textual['vecs']):\n",
    "        textual_np_vecs[i, :] = vec\n",
    "\n",
    "    return pd.concat([textual.reset_index().messages, pd.DataFrame(textual_np_vecs)], axis=1)\n",
    "\n",
    "textual_google_data = google_vec(mergedmess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('google_text.pkl','wb') as file:\n",
    "    pickle.dump(textual_google_data,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
